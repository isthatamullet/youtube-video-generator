import json


def create_colab_notebook(topic_slug, config, scenes, pexels_api_key):
    """
    Generates the structural JSON content for a Jupyter Notebook (.ipynb)
    that encapsulates the entire video rendering pipeline for a specific project.
    Uses ffmpeg-python for fast native video processing instead of MoviePy.
    """
    
    # 1. Boilerplate Setup & Dependencies
    cell_install = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 1. Setup Environment\n",
            "!apt-get install -qq fonts-liberation > /dev/null 2>&1\n",
            "!pip install -q edge-tts openai-whisper ffmpeg-python requests\n",
            "\n",
            "import os\n",
            "import json\n",
            "import asyncio\n",
            "import requests\n",
            "import random\n",
            "import subprocess\n",
            "import whisper\n",
            "import ffmpeg\n",
            "from IPython.display import Video, display, HTML\n",
            "from google.colab import drive\n",
            "\n",
            "print('Dependencies installed and imported successfully.')"
        ]
    }
    
    # 2. Inject Configuration & Data
    config_str = json.dumps(config, indent=4)
    scenes_str = json.dumps(scenes, indent=4)
    
    cell_config = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 2. Project Variables & Assets\n",
            f"TOPIC_SLUG = '{topic_slug}'\n",
            f"PEXELS_API_KEY = '{pexels_api_key}'\n",
            "\n",
            "CONFIG = " + config_str + "\n",
            "\n",
            "SCENES = " + scenes_str + "\n",
            "\n",
            "# Create a working directory\n",
            "PROJECT_DIR = f'/content/{TOPIC_SLUG}'\n",
            "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
            "print(f'Project workspace initialized at {PROJECT_DIR}')"
        ]
    }
    
    # 3. Voiceover & Subtitles Generation
    cell_audio = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 3. Generate Audio & Timestamps\n",
            "import edge_tts\n",
            "\n",
            "async def generate_voiceover():\n",
            "    full_script_text = ' '.join([scene['text'] for scene in SCENES])\n",
            "    voiceover_path = os.path.join(PROJECT_DIR, 'voiceover.mp3')\n",
            "    voice = CONFIG['audio_and_voice']['voice_model']\n",
            "    rate = CONFIG['audio_and_voice']['tts_rate']\n",
            "    pitch = CONFIG['audio_and_voice']['tts_pitch']\n",
            "    \n",
            "    print(f'Generating voiceover using {voice}...')\n",
            "    communicate = edge_tts.Communicate(full_script_text, voice, rate=rate, pitch=pitch)\n",
            "    await communicate.save(voiceover_path)\n",
            "    return voiceover_path\n",
            "\n",
            "# Colab runs an active event loop, so we await directly\n",
            "voiceover_path = await generate_voiceover()\n",
            "print('Voiceover saved.')\n",
            "\n",
            "print('Loading Whisper model for subtitle sync...')\n",
            "model = whisper.load_model('base')\n",
            "result = model.transcribe(voiceover_path, word_timestamps=True)\n",
            "\n",
            "timestamps = []\n",
            "for segment in result.get('segments', []):\n",
            "    for word in segment.get('words', []):\n",
            "        timestamps.append({\n",
            "            'word': word['word'].strip(),\n",
            "            'start': word['start'],\n",
            "            'end': word['end']\n",
            "        })\n",
            "print(f'Transcription complete. Found {len(timestamps)} words.')"
        ]
    }
    
    # 4. Pexels B-Roll
    cell_broll = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 4. Fetch Pexels B-Roll Videos\n",
            "def fetch_pexels_broll():\n",
            "    headers = {'Authorization': PEXELS_API_KEY}\n",
            "    res = CONFIG['video_settings']['resolution']\n",
            "    orientation = 'landscape' if res[0] > res[1] else 'portrait'\n",
            "    \n",
            "    b_roll_paths = []\n",
            "    for i, scene in enumerate(SCENES):\n",
            "        query = scene.get('visual_query')\n",
            "        if not query: continue\n",
            "        \n",
            "        print(f'Fetching {orientation} visual for: {query}')\n",
            "        url = f'https://api.pexels.com/videos/search?query={query}&orientation={orientation}&size=medium&per_page=5'\n",
            "        response = requests.get(url, headers=headers)\n",
            "        videos = response.json().get('videos', [])\n",
            "        \n",
            "        if not videos:\n",
            "            print(f'  -> No videos found.')\n",
            "            continue\n",
            "            \n",
            "        video = random.choice(videos)\n",
            "        video_files = video.get('video_files', [])\n",
            "        best_file = next((vf for vf in video_files if vf.get('quality') == 'hd'), video_files[0] if video_files else None)\n",
            "        \n",
            "        if best_file:\n",
            "            b_roll_path = os.path.join(PROJECT_DIR, f'scene_{i}.mp4')\n",
            "            r = requests.get(best_file['link'], stream=True)\n",
            "            with open(b_roll_path, 'wb') as f:\n",
            "                for chunk in r.iter_content(chunk_size=1024):\n",
            "                    if chunk: f.write(chunk)\n",
            "            b_roll_paths.append(b_roll_path)\n",
            "            print(f'  -> Downloaded scene_{i}')\n",
            "    return b_roll_paths\n",
            "\n",
            "b_roll_paths = fetch_pexels_broll()\n",
            "if not b_roll_paths:\n",
            "    print('ERROR: Failed to download any B-roll videos. Cannot proceed.')"
        ]
    }
    
    # 5. Scene Preview Rendering (ffmpeg-python)
    cell_scene_previews = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 5. Render Scene Previews (FFmpeg — fast native rendering)\n",
            "import time\n",
            "render_start = time.time()\n",
            "\n",
            "target_w, target_h = CONFIG['video_settings']['resolution']\n",
            "fps = CONFIG['video_settings']['fps']\n",
            "font_size = CONFIG['visuals_and_subtitles']['font_size']\n",
            "font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf'\n",
            "\n",
            "# Get total audio duration using ffprobe\n",
            "probe = ffmpeg.probe(voiceover_path)\n",
            "total_audio_duration = float(probe['format']['duration'])\n",
            "scene_duration = total_audio_duration / len(SCENES)\n",
            "\n",
            "def group_words_into_phrases(words, max_words=4):\n",
            "    \"\"\"Group individual words into subtitle phrases of max_words each.\"\"\"\n",
            "    phrases = []\n",
            "    for i in range(0, len(words), max_words):\n",
            "        chunk = words[i:i + max_words]\n",
            "        phrases.append({\n",
            "            'text': ' '.join(w['word'] for w in chunk),\n",
            "            'start': chunk[0]['start'],\n",
            "            'end': chunk[-1]['end']\n",
            "        })\n",
            "    return phrases\n",
            "\n",
            "def generate_ass_file(phrases, ass_path):\n",
            "    \"\"\"Generate an ASS subtitle file from grouped phrases.\"\"\"\n",
            "    with open(ass_path, 'w') as f:\n",
            "        f.write('[Script Info]\\n')\n",
            "        f.write(f'PlayResX: {target_w}\\n')\n",
            "        f.write(f'PlayResY: {target_h}\\n')\n",
            "        f.write('ScaledBorderAndShadow: yes\\n\\n')\n",
            "        f.write('[V4+ Styles]\\n')\n",
            "        f.write('Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\n')\n",
            "        f.write(f'Style: Default,Liberation Sans,{font_size},&H00FFFFFF,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,50,50,40,1\\n\\n')\n",
            "        f.write('[Events]\\n')\n",
            "        f.write('Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n')\n",
            "        for p in phrases:\n",
            "            s = p['start']\n",
            "            e = p['end']\n",
            "            sh = int(s // 3600)\n",
            "            sm = int((s % 3600) // 60)\n",
            "            ss = s % 60\n",
            "            eh = int(e // 3600)\n",
            "            em = int((e % 3600) // 60)\n",
            "            es = e % 60\n",
            "            start_tc = f'{sh}:{sm:02d}:{ss:05.2f}'\n",
            "            end_tc = f'{eh}:{em:02d}:{es:05.2f}'\n",
            "            text = p['text'].replace(',', '\\\\,').replace('\\n', ' ')\n",
            "            f.write(f'Dialogue: 0,{start_tc},{end_tc},Default,,0,0,0,,{text}\\n')\n",
            "\n",
            "def render_scene_preview(scene_idx):\n",
            "    \"\"\"Render a single scene preview using ffmpeg.\"\"\"\n",
            "    scene_start = scene_idx * scene_duration\n",
            "    scene_end = min((scene_idx + 1) * scene_duration, total_audio_duration)\n",
            "    actual_duration = scene_end - scene_start\n",
            "    \n",
            "    b_roll_file = b_roll_paths[scene_idx % len(b_roll_paths)]\n",
            "    preview_path = os.path.join(PROJECT_DIR, f'preview_scene_{scene_idx}.mp4')\n",
            "    \n",
            "    # Get scene-local subtitle words (shifted to start at 0)\n",
            "    scene_words = []\n",
            "    for w in timestamps:\n",
            "        if w['start'] >= scene_start and w['end'] <= scene_end:\n",
            "            scene_words.append({\n",
            "                'word': w['word'],\n",
            "                'start': w['start'] - scene_start,\n",
            "                'end': w['end'] - scene_start\n",
            "            })\n",
            "    \n",
            "    # Group words into professional-style phrase captions\n",
            "    phrases = group_words_into_phrases(scene_words)\n",
            "    \n",
            "    # Generate ASS subtitle file for this scene\n",
            "    ass_path = os.path.join(PROJECT_DIR, f'subs_scene_{scene_idx}.ass')\n",
            "    generate_ass_file(phrases, ass_path)\n",
            "    \n",
            "    # Build ffmpeg filter graph: scale -> crop -> subtitles\n",
            "    video_in = ffmpeg.input(b_roll_file, t=actual_duration)\n",
            "    audio_in = ffmpeg.input(voiceover_path, ss=scene_start, t=actual_duration)\n",
            "    \n",
            "    video_stream = (\n",
            "        video_in.video\n",
            "        .filter('scale', w=f'if(gt(iw/ih,{target_w}/{target_h}),{-2},{target_w})', h=f'if(gt(iw/ih,{target_w}/{target_h}),{target_h},{-2})')\n",
            "        .filter('crop', target_w, target_h)\n",
            "        .filter('ass', ass_path)\n",
            "    )\n",
            "    \n",
            "    (\n",
            "        ffmpeg\n",
            "        .output(video_stream, audio_in.audio, preview_path,\n",
            "                vcodec='libx264', acodec='aac',\n",
            "                movflags='+faststart', threads=4,\n",
            "                **{'b:v': '2M', 'preset': 'ultrafast'})\n",
            "        .overwrite_output()\n",
            "        .run(quiet=True)\n",
            "    )\n",
            "    return preview_path\n",
            "\n",
            "scene_previews = []\n",
            "for i in range(len(SCENES)):\n",
            "    path = render_scene_preview(i)\n",
            "    scene_previews.append(path)\n",
            "    query = SCENES[i].get('visual_query', 'N/A')\n",
            "    dur = scene_duration\n",
            "    print(f'Scene {i} rendered: {query}  ({dur:.1f}s)')\n",
            "\n",
            "elapsed = time.time() - render_start\n",
            "print(f'\\n=== All {len(scene_previews)} scene previews rendered in {elapsed:.1f}s! ===')\n",
            "print('Review each scene below. If you want to swap a scene, use Cell 6.')\n",
            "print('When satisfied, run Cell 7 to stitch the final video.\\n')\n",
            "\n",
            "# Build interactive carousel for scene review\n",
            "import base64\n",
            "\n",
            "video_b64s = []\n",
            "for path in scene_previews:\n",
            "    with open(path, 'rb') as f:\n",
            "        video_b64s.append(base64.b64encode(f.read()).decode())\n",
            "\n",
            "scenes_js_parts = []\n",
            "for i, b64 in enumerate(video_b64s):\n",
            "    q = SCENES[i]['visual_query'].replace(chr(34), chr(39))\n",
            "    scenes_js_parts.append('{b64:\"' + b64 + '\",query:\"' + q + '\",idx:' + str(i) + '}')\n",
            "scenes_js = ','.join(scenes_js_parts)\n",
            "\n",
            "n = len(scene_previews)\n",
            "html = '<div id=\"carousel\" style=\"text-align:center;background:#1a1a2e;padding:20px;border-radius:12px;max-width:640px;margin:auto\">'\n",
            "html += '<h3 id=\"scene-title\" style=\"color:#e0e0e0;margin:0 0 10px\">Scene 0</h3>'\n",
            "html += '<p id=\"scene-query\" style=\"color:#888;margin:0 0 12px;font-style:italic\"></p>'\n",
            "html += '<video id=\"scene-video\" width=\"560\" controls autoplay style=\"border-radius:8px;border:2px solid #333\"><source type=\"video/mp4\"></video>'\n",
            "html += '<div style=\"margin-top:14px;display:flex;justify-content:center;align-items:center;gap:16px\">'\n",
            "html += '<button onclick=\"prevScene()\" style=\"padding:10px 24px;font-size:18px;cursor:pointer;border:none;background:#0d7377;color:white;border-radius:8px\">\\u25c0 Prev</button>'\n",
            "html += '<span id=\"counter\" style=\"color:#aaa;font-size:16px\">1 / ' + str(n) + '</span>'\n",
            "html += '<button onclick=\"nextScene()\" style=\"padding:10px 24px;font-size:18px;cursor:pointer;border:none;background:#0d7377;color:white;border-radius:8px\">Next \\u25b6</button>'\n",
            "html += '</div></div>'\n",
            "html += '<script>'\n",
            "html += 'var scenes=[' + scenes_js + '];'\n",
            "html += 'var cur=0;'\n",
            "html += 'function showScene(i){cur=i;var v=document.getElementById(\"scene-video\");v.src=\"data:video/mp4;base64,\"+scenes[i].b64;document.getElementById(\"scene-title\").innerText=\"Scene \"+i;document.getElementById(\"scene-query\").innerText=scenes[i].query;document.getElementById(\"counter\").innerText=(i+1)+\" / \"+scenes.length;v.load();v.play();}'\n",
            "html += 'function prevScene(){if(cur>0)showScene(cur-1);}'\n",
            "html += 'function nextScene(){if(cur<scenes.length-1)showScene(cur+1);}'\n",
            "html += 'showScene(0);'\n",
            "html += '</script>'\n",
            "display(HTML(html))\n"
        ]
    }
    
    # 6. Interactive Scene Swap (ffmpeg-python)
    cell_scene_swap = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 6. Scene Swap (Optional)\n",
            "# Change the scene number and search query below, then run this cell.\n",
            "# Re-run as many times as you want to try different B-roll for any scene.\n",
            "\n",
            "SWAP_SCENE = -1  # <-- Set to the scene number you want to replace (e.g., 3)\n",
            "SWAP_QUERY = ''  # <-- Set to a new Pexels search query (e.g., 'ocean waves sunset')\n",
            "\n",
            "if SWAP_SCENE >= 0 and SWAP_QUERY:\n",
            "    print(f'Swapping Scene {SWAP_SCENE} with new query: \"{SWAP_QUERY}\"')\n",
            "    headers = {'Authorization': PEXELS_API_KEY}\n",
            "    res = CONFIG['video_settings']['resolution']\n",
            "    orientation = 'landscape' if res[0] > res[1] else 'portrait'\n",
            "    url = f'https://api.pexels.com/videos/search?query={SWAP_QUERY}&orientation={orientation}&size=medium&per_page=5'\n",
            "    response = requests.get(url, headers=headers)\n",
            "    videos = response.json().get('videos', [])\n",
            "    \n",
            "    if not videos:\n",
            "        print('No videos found for that query. Try a different search term.')\n",
            "    else:\n",
            "        video = random.choice(videos)\n",
            "        video_files = video.get('video_files', [])\n",
            "        best_file = next((vf for vf in video_files if vf.get('quality') == 'hd'), video_files[0] if video_files else None)\n",
            "        if best_file:\n",
            "            new_path = os.path.join(PROJECT_DIR, f'scene_{SWAP_SCENE}.mp4')\n",
            "            r = requests.get(best_file['link'], stream=True)\n",
            "            with open(new_path, 'wb') as f:\n",
            "                for chunk in r.iter_content(chunk_size=1024):\n",
            "                    if chunk: f.write(chunk)\n",
            "            b_roll_paths[SWAP_SCENE] = new_path\n",
            "            print(f'Downloaded new B-roll for scene {SWAP_SCENE}.')\n",
            "            \n",
            "            # Re-render just this scene preview using ffmpeg\n",
            "            preview_path = render_scene_preview(SWAP_SCENE)\n",
            "            scene_previews[SWAP_SCENE] = preview_path\n",
            "            print(f'\\nUpdated Scene {SWAP_SCENE} preview:')\n",
            "            display(Video(preview_path, embed=True, width=480))\n",
            "else:\n",
            "    print('No swap requested. Set SWAP_SCENE and SWAP_QUERY above, then re-run this cell.')\n",
            "    print('Example: SWAP_SCENE = 3, SWAP_QUERY = \"ocean waves sunset\"')\n"
        ]
    }
    
    # 7. Final Stitch (ffmpeg concat — no re-encoding!)
    cell_final_stitch = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 7. Stitch Final Video (FFmpeg concat — near-instant, no re-encoding)\n",
            "import time\n",
            "stitch_start = time.time()\n",
            "\n",
            "print('Stitching all scene previews into final video...')\n",
            "\n",
            "# Write concat list\n",
            "concat_path = os.path.join(PROJECT_DIR, 'concat_list.txt')\n",
            "with open(concat_path, 'w') as f:\n",
            "    for p in scene_previews:\n",
            "        f.write(f\"file '{p}'\\n\")\n",
            "\n",
            "output_mp4 = os.path.join(PROJECT_DIR, f'{TOPIC_SLUG}_final.mp4')\n",
            "\n",
            "# Concat with stream copy (no re-encoding!)\n",
            "(\n",
            "    ffmpeg\n",
            "    .input(concat_path, format='concat', safe=0)\n",
            "    .output(output_mp4, c='copy', movflags='+faststart')\n",
            "    .overwrite_output()\n",
            "    .run(quiet=True)\n",
            ")\n",
            "\n",
            "final_video_path = output_mp4\n",
            "elapsed = time.time() - stitch_start\n",
            "print(f'Final video stitched in {elapsed:.1f}s!')\n",
            "\n",
            "width = 400 if CONFIG['video_settings']['resolution'][0] < CONFIG['video_settings']['resolution'][1] else 800\n",
            "display(Video(final_video_path, embed=True, width=width))\n"
        ]
    }
    
    # 8. Google Drive Export
    cell_export = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 8. Export to Google Drive\n",
            "# Run this cell if you approve of the final video above!\n",
            "drive.mount('/content/drive')\n",
            "\n",
            "import shutil\n",
            f"drive_folder = '/content/drive/MyDrive/youtube-video-generator/{topic_slug}'\n",
            "os.makedirs(drive_folder, exist_ok=True)\n",
            "\n",
            "file_name = os.path.basename(final_video_path)\n",
            "dest_path = os.path.join(drive_folder, file_name)\n",
            "\n",
            "print(f'Copying to {dest_path}...')\n",
            "shutil.copy2(final_video_path, dest_path)\n",
            "print('Successfully uploaded to Google Drive!')\n"
        ]
    }
    
    # Combine cells into valid Jupyter Notebook format
    notebook = {
        "cells": [
            cell_install,
            cell_config,
            cell_audio,
            cell_broll,
            cell_scene_previews,
            cell_scene_swap,
            cell_final_stitch,
            cell_export
        ],
        "metadata": {
            "colab": {
                "name": f"{topic_slug}_generator.ipynb",
                "provenance": [],
                "gpuType": "T4"
            },
            "accelerator": "GPU",
            "kernelspec": {
                "display_name": "Python 3",
                "name": "python3"
            },
            "language_info": {
                "name": "python"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 0
    }
    
    return notebook
