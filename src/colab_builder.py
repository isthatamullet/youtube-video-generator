import json


def create_colab_notebook(topic_slug, config, scenes, pexels_api_key):
    """
    Generates the structural JSON content for a Jupyter Notebook (.ipynb)
    that encapsulates the entire video rendering pipeline for a specific project.
    Uses ffmpeg-python for fast native video processing.
    Outputs clean video + SRT captions (toggleable on YouTube).
    """
    
    # 1. Boilerplate Setup & Dependencies
    cell_install = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 1. Setup Environment\n",
            "!apt-get install -qq fonts-liberation > /dev/null 2>&1\n",
            "!pip install -q edge-tts openai-whisper ffmpeg-python requests\n",
            "\n",
            "import os\n",
            "import json\n",
            "import asyncio\n",
            "import requests\n",
            "import random\n",
            "import subprocess\n",
            "import whisper\n",
            "import ffmpeg\n",
            "from IPython.display import Video, display, HTML\n",
            "from google.colab import drive\n",
            "\n",
            "print('Dependencies installed and imported successfully.')"
        ]
    }
    
    # 2. Inject Configuration & Data
    config_str = json.dumps(config, indent=4)
    scenes_str = json.dumps(scenes, indent=4)
    
    cell_config = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 2. Project Variables & Assets\n",
            f"TOPIC_SLUG = '{topic_slug}'\n",
            f"PEXELS_API_KEY = '{pexels_api_key}'\n",
            "\n",
            "CONFIG = " + config_str + "\n",
            "\n",
            "SCENES = " + scenes_str + "\n",
            "\n",
            "# Create a working directory\n",
            "PROJECT_DIR = f'/content/{TOPIC_SLUG}'\n",
            "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
            "print(f'Project workspace initialized at {PROJECT_DIR}')"
        ]
    }
    
    # 3. Voiceover & Subtitles Generation
    cell_audio = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 3. Generate Audio & Timestamps\n",
            "import edge_tts\n",
            "\n",
            "async def generate_voiceover():\n",
            "    full_script_text = ' '.join([scene['text'] for scene in SCENES])\n",
            "    voiceover_path = os.path.join(PROJECT_DIR, 'voiceover.mp3')\n",
            "    voice = CONFIG['audio_and_voice']['voice_model']\n",
            "    rate = CONFIG['audio_and_voice']['tts_rate']\n",
            "    pitch = CONFIG['audio_and_voice']['tts_pitch']\n",
            "    \n",
            "    print(f'Generating voiceover using {voice}...')\n",
            "    communicate = edge_tts.Communicate(full_script_text, voice, rate=rate, pitch=pitch)\n",
            "    await communicate.save(voiceover_path)\n",
            "    return voiceover_path\n",
            "\n",
            "# Colab runs an active event loop, so we await directly\n",
            "voiceover_path = await generate_voiceover()\n",
            "print('Voiceover saved.')\n",
            "\n",
            "print('Loading Whisper model for subtitle sync...')\n",
            "model = whisper.load_model('base')\n",
            "result = model.transcribe(voiceover_path, word_timestamps=True)\n",
            "\n",
            "timestamps = []\n",
            "for segment in result.get('segments', []):\n",
            "    for word in segment.get('words', []):\n",
            "        timestamps.append({\n",
            "            'word': word['word'].strip(),\n",
            "            'start': word['start'],\n",
            "            'end': word['end']\n",
            "        })\n",
            "print(f'Transcription complete. Found {len(timestamps)} words.')"
        ]
    }
    
    # 4. Pexels B-Roll
    cell_broll = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 4. Fetch Pexels B-Roll Videos\n",
            "def fetch_pexels_broll():\n",
            "    headers = {'Authorization': PEXELS_API_KEY}\n",
            "    res = CONFIG['video_settings']['resolution']\n",
            "    orientation = 'landscape' if res[0] > res[1] else 'portrait'\n",
            "    \n",
            "    b_roll_paths = []\n",
            "    for i, scene in enumerate(SCENES):\n",
            "        query = scene.get('visual_query')\n",
            "        if not query: continue\n",
            "        \n",
            "        print(f'Fetching {orientation} visual for: {query}')\n",
            "        url = f'https://api.pexels.com/videos/search?query={query}&orientation={orientation}&size=medium&per_page=5'\n",
            "        response = requests.get(url, headers=headers)\n",
            "        videos = response.json().get('videos', [])\n",
            "        \n",
            "        if not videos:\n",
            "            print(f'  -> No videos found.')\n",
            "            continue\n",
            "            \n",
            "        video = random.choice(videos)\n",
            "        video_files = video.get('video_files', [])\n",
            "        best_file = next((vf for vf in video_files if vf.get('quality') == 'hd'), video_files[0] if video_files else None)\n",
            "        \n",
            "        if best_file:\n",
            "            b_roll_path = os.path.join(PROJECT_DIR, f'scene_{i}.mp4')\n",
            "            r = requests.get(best_file['link'], stream=True)\n",
            "            with open(b_roll_path, 'wb') as f:\n",
            "                for chunk in r.iter_content(chunk_size=1024):\n",
            "                    if chunk: f.write(chunk)\n",
            "            b_roll_paths.append(b_roll_path)\n",
            "            print(f'  -> Downloaded scene_{i}')\n",
            "    return b_roll_paths\n",
            "\n",
            "b_roll_paths = fetch_pexels_broll()\n",
            "if not b_roll_paths:\n",
            "    print('ERROR: Failed to download any B-roll videos. Cannot proceed.')"
        ]
    }
    
    # 5. Scene Preview Rendering (ffmpeg-python, clean — no burned-in subs)
    cell_scene_previews = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 5. Render Scene Previews (FFmpeg — clean video, captions as VTT)\n",
            "import time\n",
            "import base64\n",
            "render_start = time.time()\n",
            "\n",
            "target_w, target_h = CONFIG['video_settings']['resolution']\n",
            "fps = CONFIG['video_settings']['fps']\n",
            "\n",
            "# Get total audio duration using ffprobe\n",
            "probe = ffmpeg.probe(voiceover_path)\n",
            "total_audio_duration = float(probe['format']['duration'])\n",
            "scene_duration = total_audio_duration / len(SCENES)\n",
            "\n",
            "def group_words_into_phrases(words, max_words=4):\n",
            "    \"\"\"Group individual words into subtitle phrases of max_words each.\"\"\"\n",
            "    phrases = []\n",
            "    for i in range(0, len(words), max_words):\n",
            "        chunk = words[i:i + max_words]\n",
            "        phrases.append({\n",
            "            'text': ' '.join(w['word'] for w in chunk),\n",
            "            'start': chunk[0]['start'],\n",
            "            'end': chunk[-1]['end']\n",
            "        })\n",
            "    return phrases\n",
            "\n",
            "def format_vtt_time(seconds):\n",
            "    \"\"\"Format seconds as HH:MM:SS.mmm for VTT.\"\"\"\n",
            "    h = int(seconds // 3600)\n",
            "    m = int((seconds % 3600) // 60)\n",
            "    s = seconds % 60\n",
            "    return f'{h:02d}:{m:02d}:{s:06.3f}'\n",
            "\n",
            "def generate_vtt(phrases, vtt_path):\n",
            "    \"\"\"Generate a WebVTT subtitle file from grouped phrases.\"\"\"\n",
            "    with open(vtt_path, 'w') as f:\n",
            "        f.write('WEBVTT\\n\\n')\n",
            "        for i, p in enumerate(phrases):\n",
            "            f.write(f'{i+1}\\n')\n",
            "            f.write(f'{format_vtt_time(p[\"start\"])} --> {format_vtt_time(p[\"end\"])}\\n')\n",
            "            f.write(f'{p[\"text\"]}\\n\\n')\n",
            "\n",
            "def get_scene_phrases(scene_idx):\n",
            "    \"\"\"Get grouped phrases for a specific scene, with times relative to scene start.\"\"\"\n",
            "    scene_start = scene_idx * scene_duration\n",
            "    scene_end = min((scene_idx + 1) * scene_duration, total_audio_duration)\n",
            "    scene_words = []\n",
            "    for w in timestamps:\n",
            "        if w['start'] >= scene_start and w['end'] <= scene_end:\n",
            "            scene_words.append({\n",
            "                'word': w['word'],\n",
            "                'start': w['start'] - scene_start,\n",
            "                'end': w['end'] - scene_start\n",
            "            })\n",
            "    return group_words_into_phrases(scene_words)\n",
            "\n",
            "def render_scene_preview(scene_idx):\n",
            "    \"\"\"Render a clean scene preview (no burned-in subtitles) + generate VTT.\"\"\"\n",
            "    scene_start = scene_idx * scene_duration\n",
            "    scene_end = min((scene_idx + 1) * scene_duration, total_audio_duration)\n",
            "    actual_duration = scene_end - scene_start\n",
            "    \n",
            "    b_roll_file = b_roll_paths[scene_idx % len(b_roll_paths)]\n",
            "    preview_path = os.path.join(PROJECT_DIR, f'preview_scene_{scene_idx}.mp4')\n",
            "    vtt_path = os.path.join(PROJECT_DIR, f'subs_scene_{scene_idx}.vtt')\n",
            "    \n",
            "    # Generate VTT captions for this scene\n",
            "    phrases = get_scene_phrases(scene_idx)\n",
            "    generate_vtt(phrases, vtt_path)\n",
            "    \n",
            "    # Build ffmpeg filter graph: scale -> crop (NO subtitle burn)\n",
            "    video_in = ffmpeg.input(b_roll_file, t=actual_duration)\n",
            "    audio_in = ffmpeg.input(voiceover_path, ss=scene_start, t=actual_duration)\n",
            "    \n",
            "    video_stream = (\n",
            "        video_in.video\n",
            "        .filter('scale', w=f'if(gt(iw/ih,{target_w}/{target_h}),{-2},{target_w})', h=f'if(gt(iw/ih,{target_w}/{target_h}),{target_h},{-2})')\n",
            "        .filter('crop', target_w, target_h)\n",
            "    )\n",
            "    \n",
            "    (\n",
            "        ffmpeg\n",
            "        .output(video_stream, audio_in.audio, preview_path,\n",
            "                vcodec='libx264', acodec='aac',\n",
            "                movflags='+faststart', threads=4,\n",
            "                **{'b:v': '2M', 'preset': 'ultrafast'})\n",
            "        .overwrite_output()\n",
            "        .run(quiet=True)\n",
            "    )\n",
            "    return preview_path, vtt_path\n",
            "\n",
            "scene_previews = []\n",
            "scene_vtts = []\n",
            "for i in range(len(SCENES)):\n",
            "    vid_path, vtt_path = render_scene_preview(i)\n",
            "    scene_previews.append(vid_path)\n",
            "    scene_vtts.append(vtt_path)\n",
            "    query = SCENES[i].get('visual_query', 'N/A')\n",
            "    print(f'Scene {i} rendered: {query}  ({scene_duration:.1f}s)')\n",
            "\n",
            "elapsed = time.time() - render_start\n",
            "print(f'\\n=== All {len(scene_previews)} scene previews rendered in {elapsed:.1f}s! ===')\n",
            "print('Review each scene below. Toggle CC to preview captions.')\n",
            "print('If you want to swap a scene, use Cell 6.')\n",
            "print('When satisfied, run Cell 7 to stitch the final video.\\n')\n",
            "\n",
            "# Build interactive carousel with CC toggle\n",
            "# Encode videos and VTTs as base64 for embedding\n",
            "scenes_data = []\n",
            "for i in range(len(scene_previews)):\n",
            "    with open(scene_previews[i], 'rb') as f:\n",
            "        vid_b64 = base64.b64encode(f.read()).decode()\n",
            "    with open(scene_vtts[i], 'rb') as f:\n",
            "        vtt_b64 = base64.b64encode(f.read()).decode()\n",
            "    q = SCENES[i]['visual_query'].replace(chr(34), chr(39))\n",
            "    scenes_data.append('{v:\"' + vid_b64 + '\",c:\"' + vtt_b64 + '\",q:\"' + q + '\"}')\n",
            "\n",
            "scenes_js = ','.join(scenes_data)\n",
            "n = len(scene_previews)\n",
            "\n",
            "html = '<div id=\"carousel\" style=\"text-align:center;background:#1a1a2e;padding:20px;border-radius:12px;max-width:640px;margin:auto\">'\n",
            "html += '<h3 id=\"scene-title\" style=\"color:#e0e0e0;margin:0 0 10px\">Scene 0</h3>'\n",
            "html += '<p id=\"scene-query\" style=\"color:#888;margin:0 0 12px;font-style:italic\"></p>'\n",
            "html += '<video id=\"scene-video\" width=\"560\" controls autoplay crossorigin=\"anonymous\" style=\"border-radius:8px;border:2px solid #333\"></video>'\n",
            "html += '<div style=\"margin-top:14px;display:flex;justify-content:center;align-items:center;gap:12px\">'\n",
            "html += '<button onclick=\"prevScene()\" style=\"padding:10px 24px;font-size:18px;cursor:pointer;border:none;background:#0d7377;color:white;border-radius:8px\">\\u25c0 Prev</button>'\n",
            "html += '<span id=\"counter\" style=\"color:#aaa;font-size:16px\">1 / ' + str(n) + '</span>'\n",
            "html += '<button onclick=\"nextScene()\" style=\"padding:10px 24px;font-size:18px;cursor:pointer;border:none;background:#0d7377;color:white;border-radius:8px\">Next \\u25b6</button>'\n",
            "html += '<button id=\"cc-btn\" onclick=\"toggleCC()\" style=\"padding:10px 18px;font-size:16px;cursor:pointer;border:none;background:#e67e22;color:white;border-radius:8px;font-weight:bold\">CC \\u2713</button>'\n",
            "html += '</div></div>'\n",
            "html += '<script>'\n",
            "html += 'var scenes=[' + scenes_js + '];'\n",
            "html += 'var cur=0;var ccOn=true;'\n",
            "html += 'function showScene(i){'\n",
            "html += 'cur=i;var v=document.getElementById(\"scene-video\");'\n",
            "html += 'v.src=\"data:video/mp4;base64,\"+scenes[i].v;'\n",
            "html += 'while(v.firstChild)v.removeChild(v.firstChild);'\n",
            "html += 'var t=document.createElement(\"track\");'\n",
            "html += 't.kind=\"subtitles\";t.label=\"English\";t.srclang=\"en\";'\n",
            "html += 't.src=\"data:text/vtt;base64,\"+scenes[i].c;'\n",
            "html += 't.default=true;v.appendChild(t);'\n",
            "html += 'v.load();v.play();'\n",
            "html += 'setTimeout(function(){if(v.textTracks&&v.textTracks[0]){v.textTracks[0].mode=ccOn?\"showing\":\"hidden\";}},100);'\n",
            "html += 'document.getElementById(\"scene-title\").innerText=\"Scene \"+i;'\n",
            "html += 'document.getElementById(\"scene-query\").innerText=scenes[i].q;'\n",
            "html += 'document.getElementById(\"counter\").innerText=(i+1)+\" / \"+scenes.length;'\n",
            "html += '}'\n",
            "html += 'function prevScene(){if(cur>0)showScene(cur-1);}'\n",
            "html += 'function nextScene(){if(cur<scenes.length-1)showScene(cur+1);}'\n",
            "html += 'function toggleCC(){ccOn=!ccOn;var b=document.getElementById(\"cc-btn\");b.innerText=ccOn?\"CC \\u2713\":\"CC \\u2717\";b.style.background=ccOn?\"#e67e22\":\"#555\";var v=document.getElementById(\"scene-video\");if(v.textTracks&&v.textTracks[0]){v.textTracks[0].mode=ccOn?\"showing\":\"hidden\";}}'\n",
            "html += 'showScene(0);'\n",
            "html += '</script>'\n",
            "display(HTML(html))\n"
        ]
    }
    
    # 6. Interactive Scene Swap (ffmpeg-python)
    cell_scene_swap = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 6. Scene Swap (Optional)\n",
            "# Change the scene number and search query below, then run this cell.\n",
            "# Re-run as many times as you want to try different B-roll for any scene.\n",
            "\n",
            "SWAP_SCENE = -1  # <-- Set to the scene number you want to replace (e.g., 3)\n",
            "SWAP_QUERY = ''  # <-- Set to a new Pexels search query (e.g., 'ocean waves sunset')\n",
            "\n",
            "if SWAP_SCENE >= 0 and SWAP_QUERY:\n",
            "    print(f'Swapping Scene {SWAP_SCENE} with new query: \"{SWAP_QUERY}\"')\n",
            "    headers = {'Authorization': PEXELS_API_KEY}\n",
            "    res = CONFIG['video_settings']['resolution']\n",
            "    orientation = 'landscape' if res[0] > res[1] else 'portrait'\n",
            "    url = f'https://api.pexels.com/videos/search?query={SWAP_QUERY}&orientation={orientation}&size=medium&per_page=5'\n",
            "    response = requests.get(url, headers=headers)\n",
            "    videos = response.json().get('videos', [])\n",
            "    \n",
            "    if not videos:\n",
            "        print('No videos found for that query. Try a different search term.')\n",
            "    else:\n",
            "        video = random.choice(videos)\n",
            "        video_files = video.get('video_files', [])\n",
            "        best_file = next((vf for vf in video_files if vf.get('quality') == 'hd'), video_files[0] if video_files else None)\n",
            "        if best_file:\n",
            "            new_path = os.path.join(PROJECT_DIR, f'scene_{SWAP_SCENE}.mp4')\n",
            "            r = requests.get(best_file['link'], stream=True)\n",
            "            with open(new_path, 'wb') as f:\n",
            "                for chunk in r.iter_content(chunk_size=1024):\n",
            "                    if chunk: f.write(chunk)\n",
            "            b_roll_paths[SWAP_SCENE] = new_path\n",
            "            print(f'Downloaded new B-roll for scene {SWAP_SCENE}.')\n",
            "            \n",
            "            # Re-render this scene (clean + new VTT)\n",
            "            vid_path, vtt_path = render_scene_preview(SWAP_SCENE)\n",
            "            scene_previews[SWAP_SCENE] = vid_path\n",
            "            scene_vtts[SWAP_SCENE] = vtt_path\n",
            "            print(f'\\nUpdated Scene {SWAP_SCENE} preview:')\n",
            "            display(Video(vid_path, embed=True, width=480))\n",
            "else:\n",
            "    print('No swap requested. Set SWAP_SCENE and SWAP_QUERY above, then re-run this cell.')\n",
            "    print('Example: SWAP_SCENE = 3, SWAP_QUERY = \"ocean waves sunset\"')\n"
        ]
    }
    
    # 7. Final Stitch + SRT Generation
    cell_final_stitch = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 7. Stitch Final Video + Generate SRT Captions\n",
            "import time\n",
            "stitch_start = time.time()\n",
            "\n",
            "print('Stitching all scene previews into final video...')\n",
            "\n",
            "# Write concat list\n",
            "concat_path = os.path.join(PROJECT_DIR, 'concat_list.txt')\n",
            "with open(concat_path, 'w') as f:\n",
            "    for p in scene_previews:\n",
            "        f.write(f\"file '{p}'\\n\")\n",
            "\n",
            "output_mp4 = os.path.join(PROJECT_DIR, f'{TOPIC_SLUG}_final.mp4')\n",
            "\n",
            "# Concat with stream copy (no re-encoding!)\n",
            "(\n",
            "    ffmpeg\n",
            "    .input(concat_path, format='concat', safe=0)\n",
            "    .output(output_mp4, c='copy', movflags='+faststart')\n",
            "    .overwrite_output()\n",
            "    .run(quiet=True)\n",
            ")\n",
            "\n",
            "final_video_path = output_mp4\n",
            "\n",
            "# Generate merged SRT with global timecodes\n",
            "def format_srt_time(seconds):\n",
            "    h = int(seconds // 3600)\n",
            "    m = int((seconds % 3600) // 60)\n",
            "    s = seconds % 60\n",
            "    return f'{h:02d}:{m:02d}:{s:06.3f}'.replace('.', ',')\n",
            "\n",
            "srt_path = os.path.join(PROJECT_DIR, f'{TOPIC_SLUG}_captions.srt')\n",
            "srt_counter = 1\n",
            "with open(srt_path, 'w') as f:\n",
            "    for scene_idx in range(len(SCENES)):\n",
            "        scene_offset = scene_idx * scene_duration\n",
            "        phrases = get_scene_phrases(scene_idx)\n",
            "        for p in phrases:\n",
            "            global_start = p['start'] + scene_offset\n",
            "            global_end = p['end'] + scene_offset\n",
            "            f.write(f'{srt_counter}\\n')\n",
            "            f.write(f'{format_srt_time(global_start)} --> {format_srt_time(global_end)}\\n')\n",
            "            f.write(f'{p[\"text\"]}\\n\\n')\n",
            "            srt_counter += 1\n",
            "\n",
            "elapsed = time.time() - stitch_start\n",
            "print(f'Final video stitched in {elapsed:.1f}s!')\n",
            "print(f'SRT captions saved: {srt_path} ({srt_counter - 1} cues)')\n",
            "\n",
            "width = 400 if CONFIG['video_settings']['resolution'][0] < CONFIG['video_settings']['resolution'][1] else 800\n",
            "display(Video(final_video_path, embed=True, width=width))\n"
        ]
    }
    
    # 8. Google Drive Export (video + captions)
    cell_export = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 8. Export to Google Drive (video + captions)\n",
            "# Run this cell if you approve of the final video above!\n",
            "drive.mount('/content/drive')\n",
            "\n",
            "import shutil\n",
            "from datetime import datetime\n",
            f"drive_folder = '/content/drive/MyDrive/youtube-video-generator/{topic_slug}'\n",
            "os.makedirs(drive_folder, exist_ok=True)\n",
            "\n",
            "# Timestamp filenames so each render is preserved\n",
            "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
            "\n",
            "# Export video\n",
            "video_dest = os.path.join(drive_folder, f'{TOPIC_SLUG}_final_{ts}.mp4')\n",
            "print(f'Copying video to {video_dest}...')\n",
            "shutil.copy2(final_video_path, video_dest)\n",
            "\n",
            "# Export SRT captions\n",
            "srt_dest = os.path.join(drive_folder, f'{TOPIC_SLUG}_captions_{ts}.srt')\n",
            "print(f'Copying captions to {srt_dest}...')\n",
            "shutil.copy2(srt_path, srt_dest)\n",
            "\n",
            "print('\\nSuccessfully exported to Google Drive!')\n",
            "print(f'  Video:    {video_dest}')\n",
            "print(f'  Captions: {srt_dest}')\n",
            "print('\\nTo add captions on YouTube:')\n",
            "print('  1. Upload the video to YouTube Studio')\n",
            "print('  2. Go to Subtitles > Add > Upload file > SRT')\n",
            "print('  3. Upload the .srt file')\n"
        ]
    }
    
    # Combine cells into valid Jupyter Notebook format
    notebook = {
        "cells": [
            cell_install,
            cell_config,
            cell_audio,
            cell_broll,
            cell_scene_previews,
            cell_scene_swap,
            cell_final_stitch,
            cell_export
        ],
        "metadata": {
            "colab": {
                "name": f"{topic_slug}_generator.ipynb",
                "provenance": [],
                "gpuType": "T4"
            },
            "accelerator": "GPU",
            "kernelspec": {
                "display_name": "Python 3",
                "name": "python3"
            },
            "language_info": {
                "name": "python"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 0
    }
    
    return notebook
